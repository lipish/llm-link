# LLM Link Configuration for Zed.dev (No Authentication)
server:
  host: "localhost"
  port: 11434
  log_level: "info"

# LLM Backend Configuration
llm_backend:
  type: "Zhipu"
  api_key: "sk-your-zhipu-api-key-here"  # Replace with your Zhipu API key from https://open.bigmodel.cn/
  base_url: "https://open.bigmodel.cn/api/paas/v4"
  model: "glm-4.6"

# API Configuration
apis:
  # Ollama-compatible API (for Zed.dev)
  ollama:
    enabled: true
    path: ""
    # No API key authentication for Zed compatibility
    # api_key_header: "authorization"
    # api_key: "your-service-api-key-here"
    # Applications will use these endpoints:
    # - POST http://localhost:11434/api/generate
    # - POST http://localhost:11434/api/chat
    # - GET  http://localhost:11434/api/tags
    # - GET  http://localhost:11434/api/show/:model

  # OpenAI-compatible API (disabled for this config)
  openai:
    enabled: false
    path: "/v1"

  # Anthropic-compatible API (disabled for this config)
  anthropic:
    enabled: false
    path: "/v1"

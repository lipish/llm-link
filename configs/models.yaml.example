# Example model configuration file
# Copy this file to configs/models.yaml and customize as needed
# If this file doesn't exist, the system will use built-in minimal models
#
# Data sources (last updated 2025-01-17):
# - OpenAI: Official documentation and community reports
# - Anthropic: https://docs.claude.com/en/docs/about-claude/models/overview
# - Zhipu: https://bigmodel.cn/ and community reports
# - Ollama: https://ollama.com/search
# - Aliyun: https://help.aliyun.com/zh/model-studio/models

openai:
  models:
    # Latest GPT-5 series
    - id: "gpt-5"
      name: "GPT-5"
      description: "Best model for coding and agentic tasks across industries"
    - id: "gpt-5-mini"
      name: "GPT-5 Mini"
      description: "Faster, cheaper version of GPT-5"

    # GPT-4 series
    - id: "gpt-4o"
      name: "GPT-4o"
      description: "GPT-4 Omni model with multimodal capabilities"
    - id: "gpt-4o-mini"
      name: "GPT-4o Mini"
      description: "Smaller, faster GPT-4o model"
    - id: "gpt-4-turbo"
      name: "GPT-4 Turbo"
      description: "Latest GPT-4 Turbo model"
    - id: "gpt-4"
      name: "GPT-4"
      description: "Most capable GPT-4 model"

    # GPT-3.5 series
    - id: "gpt-3.5-turbo"
      name: "GPT-3.5 Turbo"
      description: "Fast and efficient model"
    - id: "gpt-3.5-turbo-16k"
      name: "GPT-3.5 Turbo 16K"
      description: "Extended context version"

anthropic:
  models:
    # Claude 4.5 series (latest)
    - id: "claude-sonnet-4-5-20250929"
      name: "Claude Sonnet 4.5"
      description: "Best model for complex agents and coding"
    - id: "claude-haiku-4-5-20251001"
      name: "Claude Haiku 4.5"
      description: "Fastest and most intelligent Haiku model"

    # Claude 4 series
    - id: "claude-opus-4-1-20250805"
      name: "Claude Opus 4.1"
      description: "Exceptional model for specialized complex tasks"
    - id: "claude-sonnet-4-20250514"
      name: "Claude Sonnet 4"
      description: "High-performance model"

    # Claude 3.7 series
    - id: "claude-3-7-sonnet-20250219"
      name: "Claude Sonnet 3.7"
      description: "High-performance model with extended thinking"

    # Claude 3.5 series (legacy)
    - id: "claude-3-5-sonnet-20241022"
      name: "Claude 3.5 Sonnet"
      description: "Previous generation Sonnet model"
    - id: "claude-3-5-haiku-20241022"
      name: "Claude 3.5 Haiku"
      description: "Previous generation Haiku model"

zhipu:
  models:
    # Latest GLM-4 series
    - id: "glm-4.6"
      name: "GLM-4.6"
      description: "Advanced agentic, reasoning and coding capabilities"
    - id: "glm-4-flash"
      name: "GLM-4 Flash"
      description: "Fast model for quick tasks"
    - id: "glm-4-plus"
      name: "GLM-4 Plus"
      description: "Enhanced model for complex tasks"
    - id: "glm-4"
      name: "GLM-4"
      description: "Standard model"
    - id: "glm-4-air"
      name: "GLM-4 Air"
      description: "Lightweight model"
    - id: "glm-4-long"
      name: "GLM-4 Long"
      description: "Long context model"
    - id: "glm-4-0520"
      name: "GLM-4 0520"
      description: "GLM-4 May 2024 version"

ollama:
  models:
    # Latest trending models (2025)
    - id: "gpt-oss"
      name: "GPT-OSS"
      description: "OpenAI's open-weight models for reasoning and agentic tasks"
    - id: "qwen3-vl"
      name: "Qwen 3 VL"
      description: "Most powerful vision-language model in Qwen family"
    - id: "deepseek-r1"
      name: "DeepSeek-R1"
      description: "Open reasoning models approaching O3 performance"
    - id: "qwen3-coder"
      name: "Qwen 3 Coder"
      description: "Performant long context models for agentic and coding tasks"
    - id: "gemma3"
      name: "Gemma 3"
      description: "Most capable model that runs on a single GPU"
    - id: "qwen3"
      name: "Qwen 3"
      description: "Latest generation with dense and MoE models"

    # Meta Llama series
    - id: "llama3.1"
      name: "Llama 3.1"
      description: "State-of-the-art model from Meta (8B, 70B, 405B)"
    - id: "llama3.2"
      name: "Llama 3.2"
      description: "Small models (1B and 3B) from Meta"
    - id: "llama3"
      name: "Llama 3"
      description: "Llama 3 model"
    - id: "llama2"
      name: "Llama 2"
      description: "Llama 2 model"
    - id: "codellama"
      name: "Code Llama"
      description: "Large language model for code generation"

    # Other popular models
    - id: "mistral"
      name: "Mistral"
      description: "7B model from Mistral AI"
    - id: "mixtral"
      name: "Mixtral"
      description: "Mixtral 8x7B model"
    - id: "qwen2.5"
      name: "Qwen 2.5"
      description: "Qwen 2.5 model"
    - id: "qwen2.5-coder"
      name: "Qwen 2.5 Coder"
      description: "Code-specific Qwen models with improvements"
    - id: "deepseek-coder"
      name: "DeepSeek Coder"
      description: "Code-specialized model"
    - id: "phi4"
      name: "Phi-4"
      description: "14B parameter state-of-the-art model from Microsoft"
    - id: "phi3"
      name: "Phi-3"
      description: "Microsoft Phi-3 model"
    - id: "gemma2"
      name: "Gemma 2"
      description: "Google Gemma 2 high-performing model"

aliyun:
  models:
    - id: "qwen-turbo"
      name: "Qwen Turbo"
      description: "Fast Qwen model"
    - id: "qwen-plus"
      name: "Qwen Plus"
      description: "Enhanced Qwen model"
    - id: "qwen-max"
      name: "Qwen Max"
      description: "Most capable Qwen model"
    - id: "qwen-max-longcontext"
      name: "Qwen Max Long Context"
      description: "Long context Qwen model"
    - id: "qwen2.5-72b-instruct"
      name: "Qwen 2.5 72B"
      description: "Large Qwen 2.5 model"
    - id: "qwen2.5-32b-instruct"
      name: "Qwen 2.5 32B"
      description: "Medium Qwen 2.5 model"
    - id: "qwen2.5-14b-instruct"
      name: "Qwen 2.5 14B"
      description: "Smaller Qwen 2.5 model"

# Example custom model configuration
# Copy this file to a custom location and modify as needed
# 
# This is an example of how you can create custom model configurations
# The default models are embedded in the binary at src/models/models.yaml
# 
# To use a custom configuration:
# 1. Copy this file to your desired location
# 2. Modify the models as needed
# 3. Use ModelsConfig::load_from_file() in your code to load it
#
# Note: The embedded configuration in src/models/models.yaml is used by default

openai:
  models:
    # Example: Add a custom model
    - id: "gpt-4-custom"
      name: "GPT-4 Custom"
      description: "Custom GPT-4 configuration"
    
    # Standard models (these are already in the embedded config)
    - id: "gpt-4o"
      name: "GPT-4o"
      description: "GPT-4 Omni model with multimodal capabilities"
    - id: "gpt-4"
      name: "GPT-4"
      description: "Most capable GPT-4 model"

anthropic:
  models:
    # Example: Custom Claude configuration
    - id: "claude-custom"
      name: "Claude Custom"
      description: "Custom Claude configuration"
    
    # Standard models
    - id: "claude-3-5-sonnet-20241022"
      name: "Claude 3.5 Sonnet"
      description: "Latest Claude 3.5 Sonnet model"

zhipu:
  models:
    - id: "glm-4-flash"
      name: "GLM-4 Flash"
      description: "Fast model for quick tasks"
    - id: "glm-4"
      name: "GLM-4"
      description: "Standard model"

ollama:
  models:
    # Note: For Ollama, the actual available models are determined by
    # the ollama.models() API call, not this configuration
    - id: "llama3.2"
      name: "Llama 3.2"
      description: "Latest Llama model"
    - id: "custom-model"
      name: "Custom Model"
      description: "Your custom local model"

aliyun:
  models:
    - id: "qwen-turbo"
      name: "Qwen Turbo"
      description: "Fast Qwen model"
    - id: "qwen-plus"
      name: "Qwen Plus"
      description: "Enhanced Qwen model"

# LLM Link Configuration - Optimized for Claude Code
#
# This configuration is specifically optimized for Anthropic Claude Code
# Provides pure Anthropic API with optimal settings for code analysis

# Application metadata
app:
  name: "Claude Code"
  description: "Anthropic Claude for code generation and analysis"
  version: "1.0"
  documentation: "https://github.com/your-repo/llm-link/docs/apps/claude-code.md"

# Server configuration - Dedicated port for Claude
server:
  host: "0.0.0.0"
  port: 8089
  log_level: "info"

# LLM backend configuration
llm_backend:
  type: "Zhipu"
  base_url: "https://open.bigmodel.cn/api/paas/v4"
  api_key: "${ZHIPU_API_KEY}"
  model: "glm-4-plus"  # Use plus model for better code analysis

# API configuration - Pure Anthropic API only
apis:
  anthropic:
    enabled: true
    path: "/anthropic"
    api_key_header: "x-api-key"
    api_key: "${ANTHROPIC_API_KEY}"
  
  openai:
    enabled: false
  
  ollama:
    enabled: false

# Client adapter - Standard adapter for Anthropic
client_adapters:
  default_adapter: "standard"
  
  zed:
    enabled: false

# Claude Code specific optimizations
claude_optimizations:
  # Enable streaming for better user experience
  enable_streaming: true
  # Optimize for code analysis and generation
  code_analysis_mode: true
  # Use Claude-specific response format
  response_format: "anthropic_standard"
  # Longer context for code analysis
  max_context_length: 8192

# Model configurations for LLM Link
# This file contains model lists for different LLM providers
# 
# Data sources (last updated 2025-01-17):
# - OpenAI: Official documentation and community reports
# - Anthropic: https://docs.claude.com/en/docs/about-claude/models/overview
# - Zhipu: https://bigmodel.cn/ and community reports
# - Ollama: https://ollama.com/search (Note: actual available models depend on local installation)
# - Aliyun: https://help.aliyun.com/zh/model-studio/models

openai:
  models:
    - id: "gpt-4o"
      name: "GPT-4o"
      description: "GPT-4 Omni model with multimodal capabilities"
    - id: "gpt-4o-mini"
      name: "GPT-4o Mini"
      description: "Smaller, faster GPT-4o model"
    - id: "gpt-4-turbo"
      name: "GPT-4 Turbo"
      description: "Latest GPT-4 Turbo model"
    - id: "gpt-4"
      name: "GPT-4"
      description: "Most capable GPT-4 model"
    - id: "gpt-3.5-turbo"
      name: "GPT-3.5 Turbo"
      description: "Fast and efficient model"

anthropic:
  models:
    - id: "claude-3-5-sonnet-20241022"
      name: "Claude 3.5 Sonnet"
      description: "Latest Claude 3.5 Sonnet model"
    - id: "claude-3-5-haiku-20241022"
      name: "Claude 3.5 Haiku"
      description: "Fast and efficient Claude model"
    - id: "claude-3-opus-20240229"
      name: "Claude 3 Opus"
      description: "Most capable Claude 3 model"
    - id: "claude-3-sonnet-20240229"
      name: "Claude 3 Sonnet"
      description: "Balanced Claude 3 model"
    - id: "claude-3-haiku-20240307"
      name: "Claude 3 Haiku"
      description: "Fastest Claude 3 model"

zhipu:
  models:
    - id: "glm-4-flash"
      name: "GLM-4 Flash"
      description: "Fast model for quick tasks"
    - id: "glm-4-plus"
      name: "GLM-4 Plus"
      description: "Enhanced model for complex tasks"
    - id: "glm-4"
      name: "GLM-4"
      description: "Standard model"
    - id: "glm-4-air"
      name: "GLM-4 Air"
      description: "Lightweight model"
    - id: "glm-4-long"
      name: "GLM-4 Long"
      description: "Long context model"

# Note: For Ollama, this list represents commonly available models
# The actual available models will be determined by querying the Ollama API
# to get the list of locally installed models
ollama:
  models:
    - id: "llama3.2"
      name: "Llama 3.2"
      description: "Latest Llama model (1B, 3B)"
    - id: "llama3.1"
      name: "Llama 3.1"
      description: "Llama 3.1 model (8B, 70B, 405B)"
    - id: "llama3"
      name: "Llama 3"
      description: "Llama 3 model (8B, 70B)"
    - id: "llama2"
      name: "Llama 2"
      description: "Llama 2 model (7B, 13B, 70B)"
    - id: "codellama"
      name: "Code Llama"
      description: "Code-specialized Llama model"
    - id: "mistral"
      name: "Mistral"
      description: "Mistral 7B model"
    - id: "mixtral"
      name: "Mixtral"
      description: "Mixtral 8x7B model"
    - id: "qwen2.5"
      name: "Qwen 2.5"
      description: "Qwen 2.5 model"
    - id: "qwen2.5-coder"
      name: "Qwen 2.5 Coder"
      description: "Code-specific Qwen models"
    - id: "deepseek-coder"
      name: "DeepSeek Coder"
      description: "Code-specialized model"
    - id: "phi3"
      name: "Phi-3"
      description: "Microsoft Phi-3 model"
    - id: "gemma2"
      name: "Gemma 2"
      description: "Google Gemma 2 model"

aliyun:
  models:
    - id: "qwen-turbo"
      name: "Qwen Turbo"
      description: "Fast Qwen model"
    - id: "qwen-plus"
      name: "Qwen Plus"
      description: "Enhanced Qwen model"
    - id: "qwen-max"
      name: "Qwen Max"
      description: "Most capable Qwen model"
    - id: "qwen-max-longcontext"
      name: "Qwen Max Long Context"
      description: "Long context Qwen model"
    - id: "qwen2.5-72b-instruct"
      name: "Qwen 2.5 72B"
      description: "Large Qwen 2.5 model"
    - id: "qwen2.5-32b-instruct"
      name: "Qwen 2.5 32B"
      description: "Medium Qwen 2.5 model"

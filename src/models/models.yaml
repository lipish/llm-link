# Model configurations for LLM Link
# This file contains model lists for different LLM providers
#
# Data sources (last updated 2025-10-24):
# - OpenAI: https://platform.openai.com/docs/models
# - Anthropic: https://docs.anthropic.com/claude/docs/models-overview
# - Zhipu: https://bigmodel.cn/ and community reports
# - Ollama: https://ollama.com/search (Note: actual available models depend on local installation)
# - Aliyun: https://help.aliyun.com/zh/model-studio/models
# - Moonshot: https://platform.moonshot.cn/docs/introduction#%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8
# - Longcat: https://longcat.chat/platform/docs/zh/#%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B
# - Tencent: https://cloud.tencent.com/document/product/1729/104753
# - Volcengine: https://www.volcengine.com/docs/82379/1330310
# - Minimax: https://platform.minimaxi.com/docs/guides/text-generation

openai:
  models:
    - id: "gpt-4o"
      name: "GPT-4o"
      description: "GPT-4 Omni - Multimodal flagship model"
    - id: "gpt-4o-mini"
      name: "GPT-4o Mini"
      description: "Affordable and intelligent small model"
    - id: "gpt-4-turbo"
      name: "GPT-4 Turbo"
      description: "Latest GPT-4 Turbo with vision"
    - id: "gpt-4"
      name: "GPT-4"
      description: "Most capable GPT-4 model"
    - id: "gpt-3.5-turbo"
      name: "GPT-3.5 Turbo"
      description: "Fast and efficient model"
    - id: "o1-preview"
      name: "o1 Preview"
      description: "Reasoning model for complex tasks"
    - id: "o1-mini"
      name: "o1 Mini"
      description: "Faster reasoning model"

anthropic:
  models:
    - id: "claude-3-5-sonnet-20241022"
      name: "Claude 3.5 Sonnet"
      description: "Latest Claude 3.5 Sonnet model with improved capabilities"
    - id: "claude-3-5-haiku-20241022"
      name: "Claude 3.5 Haiku"
      description: "Fast and efficient Claude 3.5 model"
    - id: "claude-3-opus-20240229"
      name: "Claude 3 Opus"
      description: "Most capable Claude 3 model"
    - id: "claude-3-sonnet-20240229"
      name: "Claude 3 Sonnet"
      description: "Balanced Claude 3 model"
    - id: "claude-3-haiku-20240307"
      name: "Claude 3 Haiku"
      description: "Fast Claude 3 model"

zhipu:
  models:
    - id: "glm-4.6"
      name: "GLM-4.6"
      description: "Latest flagship model with 200K context, advanced coding ability"
    - id: "glm-4.5"
      name: "GLM-4.5"
      description: "Strong performance with powerful reasoning and code generation, 128K context"
    - id: "glm-4.5-x"
      name: "GLM-4.5-X"
      description: "Ultra-fast version with 128K context"
    - id: "glm-4.5-air"
      name: "GLM-4.5 Air"
      description: "Best performance at same parameter scale, 128K context"
    - id: "glm-4.5-airx"
      name: "GLM-4.5 AirX"
      description: "Fast inference with cost-effective pricing"
    - id: "glm-4.5-flash"
      name: "GLM-4.5 Flash"
      description: "Free model with 128K context"

# Note: Ollama models are determined dynamically by querying the Ollama API
# to get the list of locally installed models. No static list is needed here.
ollama:
  models: []

aliyun:
  models:
    - id: "qwen3-max"
      name: "Qwen3 Max"
      description: "Latest and most capable Qwen3 model, 262K context"
    - id: "qwen3-max-2025-09-23"
      name: "Qwen3 Max 2025-09-23"
      description: "Snapshot version of Qwen3 Max"
    - id: "qwen3-max-preview"
      name: "Qwen3 Max Preview"
      description: "Preview version of Qwen3 Max"
    - id: "qwen-turbo"
      name: "Qwen Turbo"
      description: "Fast Qwen model"
    - id: "qwen-plus"
      name: "Qwen Plus"
      description: "Enhanced Qwen model"
    - id: "qwen-max"
      name: "Qwen Max"
      description: "Most capable Qwen model"
    - id: "qwen-max-longcontext"
      name: "Qwen Max Long Context"
      description: "Long context Qwen model"
    - id: "qwen-omni-turbo"
      name: "Qwen Omni Turbo"
      description: "Multimodal model accepting multiple data types"

moonshot:
  models:
    - id: "kimi-k2-turbo-preview"
      name: "Kimi K2 Turbo Preview"
      description: "Recommended model with 262K context, high speed version"
    - id: "kimi-k2-0905-preview"
      name: "Kimi K2 0905 Preview"
      description: "262K context model with enhanced coding ability"
    - id: "kimi-k2-0711-preview"
      name: "Kimi K2 0711 Preview"
      description: "131K context model"

minimax:
  models:
    - id: "MiniMax-M2"
      name: "MiniMax M2"
      description: "Flagship model with MoE architecture, 230B total parameters, 10B activated, 204K context window"

longcat:
  models:
    - id: "LongCat-Flash-Chat"
      name: "LongCat Flash Chat"
      description: "High-performance general dialogue model"
    - id: "LongCat-Flash-Thinking"
      name: "LongCat Flash Thinking"
      description: "Deep thinking model"

tencent:
  models:
    - id: "hunyuan-t1-latest"
      name: "Hunyuan T1"
      description: "Reasoning model with extended inference capability"
    - id: "hunyuan-a13b"
      name: "Hunyuan A13B"
      description: "Mixed reasoning model, 80B total parameters, 13B activated"
    - id: "hunyuan-turbos-latest"
      name: "Hunyuan Turbos"
      description: "Flagship model with enhanced thinking capability"
    - id: "hunyuan-large"
      name: "Hunyuan Large"
      description: "389B parameters, 52B activated"
    - id: "hunyuan-standard-256K"
      name: "Hunyuan Standard 256K"
      description: "Long context support up to 250K tokens"
    - id: "hunyuan-lite"
      name: "Hunyuan Lite"
      description: "MOE structure with 256K context window"
    - id: "hunyuan-translation"
      name: "Hunyuan Translation"
      description: "33 languages + 5 ethnic languages support"
    - id: "hunyuan-role"
      name: "Hunyuan Role"
      description: "Role-playing specialized model"
    - id: "hunyuan-functioncall"
      name: "Hunyuan FunctionCall"
      description: "MOE architecture for function calling"
    - id: "hunyuan-code"
      name: "Hunyuan Code"
      description: "Code generation model"

volcengine:
  models:
    - id: "doubao-seed-1.6"
      name: "Doubao Seed 1.6"
      description: "Latest Seed 1.6 flagship model"
    - id: "doubao-seed-code-preview-latest"
      name: "Doubao Seed Code Preview"
      description: "Code-specialized Seed model (preview, latest)"
    - id: "doubao-seed-1.6-vision"
      name: "Doubao Seed 1.6 Vision"
      description: "Seed 1.6 with vision capabilities"
    - id: "doubao-seed-1.6-lite"
      name: "Doubao Seed 1.6 Lite"
      description: "Lightweight version of Seed 1.6"
    - id: "doubao-seed-1.6-flash"
      name: "Doubao Seed 1.6 Flash"
      description: "Fast inference version of Seed 1.6"
    - id: "doubao-seed-1.6-thinking"
      name: "Doubao Seed 1.6 Thinking"
      description: "Deep reasoning version of Seed 1.6"
    - id: "doubao-seed-translation"
      name: "Doubao Seed Translation"
      description: "Translation specialized model"

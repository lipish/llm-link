use serde::{Deserialize, Serialize};
use crate::config::{Config, ServerConfig, LlmBackendConfig, ApiConfigs, OpenAiApiConfig, OllamaApiConfig, AnthropicApiConfig, ClientAdapterConfigs, ZedAdapterConfig};

/// æ”¯æŒçš„åº”ç”¨ç±»å‹
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum SupportedApp {
    /// Codex CLI - OpenAI API å®¢æˆ·ç«¯
    CodexCLI,
    /// Claude Code - Anthropic å®¢æˆ·ç«¯
    ClaudeCode,
    /// Zed.dev - Ollama API å®¢æˆ·ç«¯
    ZedDev,
}

impl SupportedApp {
    /// ä»å­—ç¬¦ä¸²è§£æåº”ç”¨ç±»å‹
    pub fn from_str(s: &str) -> Option<Self> {
        match s.to_lowercase().as_str() {
            "codex-cli" | "codex" => Some(Self::CodexCLI),
            "claude-code" | "claude" => Some(Self::ClaudeCode),
            "zed-dev" | "zed" => Some(Self::ZedDev),
            _ => None,
        }
    }

    /// è·å–åº”ç”¨åç§°
    pub fn name(&self) -> &'static str {
        match self {
            Self::CodexCLI => "codex-cli",
            Self::ClaudeCode => "claude-code",
            Self::ZedDev => "zed-dev",
        }
    }

    /// è·å–æ‰€æœ‰æ”¯æŒçš„åº”ç”¨
    pub fn all() -> Vec<Self> {
        vec![
            Self::CodexCLI,
            Self::ClaudeCode,
            Self::ZedDev,
        ]
    }
}

/// åº”ç”¨é…ç½®ç”Ÿæˆå™¨
pub struct AppConfigGenerator;

impl AppConfigGenerator {
    /// ä¸ºæŒ‡å®šåº”ç”¨ç”Ÿæˆé…ç½®
    pub fn generate_config(app: &SupportedApp, cli_api_key: Option<&str>) -> Config {
        match app {
            SupportedApp::CodexCLI => Self::codex_cli_config(cli_api_key),
            SupportedApp::ClaudeCode => Self::claude_code_config(cli_api_key),
            SupportedApp::ZedDev => Self::zed_dev_config(cli_api_key),
        }
    }

    /// è§£æç¯å¢ƒå˜é‡æ¨¡æ¿ï¼Œæ”¯æŒ CLI å‚æ•°è¦†ç›–
    fn resolve_env_var(template: &str, cli_api_key: Option<&str>) -> String {
        if template.starts_with("${") && template.ends_with("}") {
            let var_name = &template[2..template.len()-1];

            // å¦‚æœæ˜¯ LLM_LINK_API_KEY ä¸”æä¾›äº† CLI å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ CLI å‚æ•°
            if var_name == "LLM_LINK_API_KEY" {
                if let Some(cli_key) = cli_api_key {
                    return cli_key.to_string();
                }
            }

            // å¦åˆ™å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
            std::env::var(var_name).unwrap_or_else(|_| {
                eprintln!("Warning: Environment variable '{}' not found, using placeholder", var_name);
                template.to_string()
            })
        } else {
            template.to_string()
        }
    }

    /// Codex CLI é…ç½®
    fn codex_cli_config(cli_api_key: Option<&str>) -> Config {
        Config {
            server: ServerConfig {
                host: "0.0.0.0".to_string(),
                port: 8088,
                log_level: "info".to_string(),
            },
            llm_backend: LlmBackendConfig::Zhipu {
                api_key: Self::resolve_env_var("${ZHIPU_API_KEY}", cli_api_key),
                base_url: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
                model: "glm-4-flash".to_string(),
            },
            apis: ApiConfigs {
                openai: Some(OpenAiApiConfig {
                    enabled: true,
                    path: "/v1".to_string(),
                    api_key_header: Some("Authorization".to_string()),
                    api_key: Some(Self::resolve_env_var("${LLM_LINK_API_KEY}", cli_api_key)),
                }),
                ollama: Some(OllamaApiConfig {
                    enabled: false,
                    path: "/ollama".to_string(),
                    api_key_header: None,
                    api_key: None,
                }),
                anthropic: Some(AnthropicApiConfig {
                    enabled: false,
                    path: "/anthropic".to_string(),
                    api_key_header: None,
                }),
            },
            client_adapters: Some(ClientAdapterConfigs {
                default_adapter: Some("openai".to_string()),
                force_adapter: Some("openai".to_string()),
                zed: Some(ZedAdapterConfig {
                    enabled: false,
                    force_images_field: Some(false),
                    preferred_format: Some("json".to_string()),
                }),
            }),
        }
    }

    /// Zed.dev é…ç½®
    fn zed_dev_config(cli_api_key: Option<&str>) -> Config {
        Config {
            server: ServerConfig {
                host: "0.0.0.0".to_string(),
                port: 11434,
                log_level: "info".to_string(),
            },
            llm_backend: LlmBackendConfig::Zhipu {
                api_key: Self::resolve_env_var("${ZHIPU_API_KEY}", cli_api_key),
                base_url: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
                model: "glm-4-flash".to_string(),
            },
            apis: ApiConfigs {
                openai: Some(OpenAiApiConfig {
                    enabled: false,
                    path: "/v1".to_string(),
                    api_key_header: None,
                    api_key: None,
                }),
                ollama: Some(OllamaApiConfig {
                    enabled: true,
                    path: "/api".to_string(),
                    api_key_header: None,
                    api_key: None,
                }),
                anthropic: Some(AnthropicApiConfig {
                    enabled: false,
                    path: "/anthropic".to_string(),
                    api_key_header: None,
                }),
            },
            client_adapters: Some(ClientAdapterConfigs {
                default_adapter: Some("zed".to_string()),
                force_adapter: Some("zed".to_string()),
                zed: Some(ZedAdapterConfig {
                    enabled: true,
                    force_images_field: Some(true),
                    preferred_format: Some("ndjson".to_string()),
                }),
            }),
        }
    }

    /// Claude Code é…ç½®
    fn claude_code_config(cli_api_key: Option<&str>) -> Config {
        Config {
            server: ServerConfig {
                host: "0.0.0.0".to_string(),
                port: 8089,
                log_level: "info".to_string(),
            },
            llm_backend: LlmBackendConfig::Zhipu {
                api_key: Self::resolve_env_var("${ZHIPU_API_KEY}", cli_api_key),
                base_url: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
                model: "glm-4-plus".to_string(),
            },
            apis: ApiConfigs {
                openai: Some(OpenAiApiConfig {
                    enabled: false,
                    path: "/v1".to_string(),
                    api_key_header: None,
                    api_key: None,
                }),
                ollama: Some(OllamaApiConfig {
                    enabled: false,
                    path: "/ollama".to_string(),
                    api_key_header: None,
                    api_key: None,
                }),
                anthropic: Some(AnthropicApiConfig {
                    enabled: true,
                    path: "/anthropic".to_string(),
                    api_key_header: Some("x-api-key".to_string()),
                }),
            },
            client_adapters: Some(ClientAdapterConfigs {
                default_adapter: Some("standard".to_string()),
                force_adapter: None,
                zed: Some(ZedAdapterConfig {
                    enabled: false,
                    force_images_field: Some(false),
                    preferred_format: Some("json".to_string()),
                }),
            }),
        }
    }


    /// ç”Ÿæˆå¤šåè®®é…ç½®
    pub fn generate_protocol_config(protocols: &[String], cli_api_key: Option<&str>) -> Config {
        let mut openai_config = None;
        let mut ollama_config = None;
        let mut anthropic_config = None;

        // æ ¹æ®åè®®åˆ—è¡¨å¯ç”¨ç›¸åº”çš„ API
        for protocol in protocols {
            match protocol.to_lowercase().as_str() {
                "openai" => {
                    openai_config = Some(OpenAiApiConfig {
                        enabled: true,
                        path: "/v1".to_string(),
                        api_key_header: Some("Authorization".to_string()),
                        api_key: Some(Self::resolve_env_var("${LLM_LINK_API_KEY}", cli_api_key)),
                    });
                },
                "ollama" => {
                    ollama_config = Some(OllamaApiConfig {
                        enabled: true,
                        path: "/ollama".to_string(),
                        api_key_header: None,
                        api_key: None,
                    });
                },
                "anthropic" => {
                    anthropic_config = Some(AnthropicApiConfig {
                        enabled: true,
                        path: "/anthropic".to_string(),
                        api_key_header: Some("x-api-key".to_string()),
                    });
                },
                _ => {
                    eprintln!("Warning: Unknown protocol '{}', ignoring", protocol);
                }
            }
        }

        Config {
            server: ServerConfig {
                host: "0.0.0.0".to_string(),
                port: 11434,
                log_level: "info".to_string(),
            },
            llm_backend: LlmBackendConfig::Zhipu {
                api_key: Self::resolve_env_var("${ZHIPU_API_KEY}", cli_api_key),
                base_url: Some("https://open.bigmodel.cn/api/paas/v4".to_string()),
                model: "glm-4-flash".to_string(),
            },
            apis: ApiConfigs {
                openai: openai_config,
                ollama: ollama_config,
                anthropic: anthropic_config,
            },
            client_adapters: Some(ClientAdapterConfigs {
                default_adapter: Some("auto".to_string()),
                force_adapter: None,
                zed: Some(ZedAdapterConfig {
                    enabled: true,
                    force_images_field: Some(true),
                    preferred_format: Some("ndjson".to_string()),
                }),
            }),
        }
    }
}

/// åº”ç”¨ä¿¡æ¯æä¾›å™¨
pub struct AppInfoProvider;

impl AppInfoProvider {
    /// è·å–åº”ç”¨çš„æ¨èé…ç½®è¯´æ˜
    pub fn get_app_info(app: &SupportedApp) -> AppInfo {
        match app {
            SupportedApp::CodexCLI => AppInfo {
                name: "Codex CLI".to_string(),
                description: "GitHub Codex CLI tool for AI-powered coding assistance".to_string(),
                port: 8088,
                protocol: "OpenAI API".to_string(),
                endpoints: vec![
                    "POST /v1/chat/completions".to_string(),
                    "GET /v1/models".to_string(),
                ],
                auth_required: true,
                env_vars: vec!["ZHIPU_API_KEY".to_string(), "LLM_LINK_API_KEY".to_string()],
                example_usage: "codex --profile glm_4_flash \"Write a Python function\"".to_string(),
            },
            SupportedApp::ClaudeCode => AppInfo {
                name: "Claude Code".to_string(),
                description: "Anthropic Claude for code generation and analysis".to_string(),
                port: 8089,
                protocol: "Anthropic API".to_string(),
                endpoints: vec![
                    "POST /anthropic/messages".to_string(),
                    "GET /anthropic/models".to_string(),
                ],
                auth_required: true,
                env_vars: vec!["ZHIPU_API_KEY".to_string(), "ANTHROPIC_API_KEY".to_string()],
                example_usage: "claude-code --model claude-3 \"Analyze this code\"".to_string(),
            },
            SupportedApp::ZedDev => AppInfo {
                name: "Zed.dev".to_string(),
                description: "Zed editor with AI assistant integration".to_string(),
                port: 11434,
                protocol: "Ollama API".to_string(),
                endpoints: vec![
                    "POST /api/chat".to_string(),
                    "GET /api/tags".to_string(),
                ],
                auth_required: false,
                env_vars: vec!["ZHIPU_API_KEY".to_string()],
                example_usage: "Configure in Zed settings: \"api_url\": \"http://localhost:11434\"".to_string(),
            },
        }
    }
}

/// åº”ç”¨ä¿¡æ¯ç»“æ„
#[derive(Debug, Clone)]
pub struct AppInfo {
    pub name: String,
    pub description: String,
    pub port: u16,
    pub protocol: String,
    pub endpoints: Vec<String>,
    pub auth_required: bool,
    pub env_vars: Vec<String>,
    pub example_usage: String,
}

/// ç¯å¢ƒå˜é‡æ£€æŸ¥å™¨
pub struct EnvChecker;

impl EnvChecker {
    /// æ£€æŸ¥åº”ç”¨æ‰€éœ€çš„ç¯å¢ƒå˜é‡ï¼Œè€ƒè™‘ CLI å‚æ•°
    pub fn check_env_vars(app: &SupportedApp, cli_api_key: Option<&str>) -> Result<(), Vec<String>> {
        let app_info = AppInfoProvider::get_app_info(app);
        let mut missing_vars = Vec::new();

        // æ£€æŸ¥åº”ç”¨æ‰€éœ€çš„æ‰€æœ‰ç¯å¢ƒå˜é‡
        for env_var in &app_info.env_vars {
            // ç‰¹æ®Šå¤„ç† LLM_LINK_API_KEYï¼šå¦‚æœæä¾›äº† CLI å‚æ•°ï¼Œåˆ™ä¸éœ€è¦ç¯å¢ƒå˜é‡
            if env_var == "LLM_LINK_API_KEY" && cli_api_key.is_some() {
                continue;
            }

            // æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å­˜åœ¨
            if std::env::var(env_var).is_err() {
                missing_vars.push(env_var.clone());
            }
        }

        if missing_vars.is_empty() {
            Ok(())
        } else {
            Err(missing_vars)
        }
    }

    /// æ˜¾ç¤ºç¯å¢ƒå˜é‡è®¾ç½®æŒ‡å—
    pub fn show_env_guide(app: &SupportedApp) {
        let app_info = AppInfoProvider::get_app_info(app);

        println!("ğŸ”§ Environment Variables Required for {}:", app_info.name);
        println!();

        // æ˜¾ç¤ºæ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡
        for env_var in &app_info.env_vars {
            match env_var.as_str() {
                "ZHIPU_API_KEY" => println!("export ZHIPU_API_KEY=\"your-zhipu-api-key\""),
                "LLM_LINK_API_KEY" => println!("export LLM_LINK_API_KEY=\"your-auth-token\""),
                "ANTHROPIC_API_KEY" => println!("export ANTHROPIC_API_KEY=\"your-anthropic-api-key\""),
                _ => println!("export {}=\"your-{}-here\"", env_var, env_var.to_lowercase().replace('_', "-")),
            }
        }
        println!();

        // åº”ç”¨ç‰¹å®šçš„æç¤º
        match app {
            SupportedApp::CodexCLI => {
                println!("ğŸ’¡ Alternative: Use CLI parameter instead of environment variable:");
                println!("   ./target/release/llm-link --app codex-cli --api-key \"your-auth-token\"");
                println!();
                println!("ğŸ’¡ The LLM_LINK_API_KEY can be any string you choose for authentication.");
            },
            SupportedApp::ZedDev => {
                println!("ğŸ’¡ Zed.dev doesn't require additional authentication tokens.");
            },
            SupportedApp::ClaudeCode => {
                println!("ğŸ’¡ You need both Zhipu and Anthropic API keys for Claude Code mode.");
            },
        }

        println!();
        println!("ğŸš€ Start command:");
        println!("   ./target/release/llm-link --app {}", app.name());
        println!();
        println!("ğŸ“– Example usage:");
        println!("   {}", app_info.example_usage);
        println!();
    }
}

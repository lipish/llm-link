# Streaming Tool Calls ä¿®å¤

## ğŸ” é—®é¢˜å‘ç°

### ç°è±¡
Codex åœ¨æµå¼æ¨¡å¼ä¸‹ä¸æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œåªæ˜¾ç¤ºæ–‡æœ¬ã€‚

### åŸå§‹å“åº”
GLM-4.6 è¿”å›çš„æµå¼å“åº”ï¼š
```json
// Chunk 1-26: content
{"delta": {"content": "I'll help you..."}, "finish_reason": null}

// Chunk 27: tool_calls  
{"delta": {"tool_calls": [...]}, "finish_reason": null}

// Chunk 28: ç»“æŸ
{"delta": {}, "finish_reason": "stop"}  // âŒ é”™è¯¯ï¼åº”è¯¥æ˜¯ "tool_calls"
```

## ğŸ¯ æ ¹æœ¬åŸå› 

é€šè¿‡åˆ†æ Codex æºä»£ç ï¼ˆ`codex-rs/core/src/chat_completions.rs`ï¼‰ï¼Œå‘ç°å…³é”®é€»è¾‘ï¼š

```rust
// Codex çš„åˆ¤æ–­é€»è¾‘ï¼ˆç¬¬ 587-640 è¡Œï¼‰
if let Some(finish_reason) = choice.get("finish_reason") {
    match finish_reason {
        "tool_calls" if fn_call_state.active => {
            // âœ… æ‰§è¡Œå·¥å…·
            let item = ResponseItem::FunctionCall { ... };
            tx_event.send(Ok(ResponseEvent::OutputItemDone(item))).await;
        }
        "stop" => {
            // âŒ åªæ˜¾ç¤ºæ–‡æœ¬
            if !assistant_text.is_empty() {
                let item = ResponseItem::Message { ... };
                tx_event.send(Ok(ResponseEvent::OutputItemDone(item))).await;
            }
        }
    }
}
```

**é—®é¢˜**ï¼š
- GLM-4.6 è¿”å› `finish_reason: "stop"`ï¼ˆå³ä½¿æœ‰ tool_callsï¼‰
- Codex æ£€æŸ¥ `finish_reason` æ¥å†³å®šè¡Œä¸º
- `"stop"` â†’ æ˜¾ç¤ºæ–‡æœ¬ï¼Œä¸æ‰§è¡Œå·¥å…·
- `"tool_calls"` â†’ æ‰§è¡Œå·¥å…·

## âœ… è§£å†³æ–¹æ¡ˆ

llm-link å®ç°äº†**æ™ºèƒ½ `finish_reason` ä¿®æ­£**ï¼š

### å®ç°é€»è¾‘

```rust
// src/client.rs
let mut has_tool_calls = false;

// 1. æ£€æµ‹ tool_calls
if let Some(tool_calls) = &first_choice.delta.tool_calls {
    has_tool_calls = true;
}

// 2. ä¿®æ­£ finish_reason
let finish_reason = if has_tool_calls {
    "tool_calls"  // âœ… ä¿®æ­£ä¸ºæ­£ç¡®å€¼
} else {
    "stop"
};

// 3. å‘é€æœ€ç»ˆ chunk
let final_chunk = json!({
    "choices": [{
        "delta": {},
        "finish_reason": finish_reason  // ä½¿ç”¨ä¿®æ­£åçš„å€¼
    }]
});
```

### æ•ˆæœå¯¹æ¯”

**ä¿®å¤å‰**ï¼š
```json
{"delta": {"tool_calls": [...]}, "finish_reason": null}
{"delta": {}, "finish_reason": "stop"}  // âŒ Codex ä¸æ‰§è¡Œå·¥å…·
```

**ä¿®å¤å**ï¼š
```json
{"delta": {"tool_calls": [...]}, "finish_reason": null}
{"delta": {}, "finish_reason": "tool_calls"}  // âœ… Codex æ‰§è¡Œå·¥å…·ï¼
```

## ğŸ“Š æµ‹è¯•éªŒè¯

```bash
# æµ‹è¯•è„šæœ¬
./tests/test_codex_simulation.sh

# ç»“æœ
data: {"choices":[{"delta":{"content":"I'll help you..."},...}]}
...
data: {"choices":[{"delta":{"tool_calls":[...]},...}]}
data: {"choices":[{"delta":{},"finish_reason":"tool_calls",...}]}  âœ…
data: [DONE]
```

**æ—¥å¿—è¾“å‡º**ï¼š
```
ğŸ”§ Received chunk #27 with tool_calls: 1 calls
ğŸ¯ Setting finish_reason to 'tool_calls' (detected tool_calls in stream)
```

## ğŸ‰ ä¼˜åŠ¿

### âœ… ä¿ç•™å®Œæ•´ä½“éªŒ
- ç”¨æˆ·èƒ½çœ‹åˆ° LLM çš„æ€è€ƒè¿‡ç¨‹ï¼š"I'll help you check the project..."
- å·¥å…·è°ƒç”¨æ­£å¸¸æ‰§è¡Œ
- å®æ—¶æµå¼å“åº”ï¼Œæ— å»¶è¿Ÿ

### âœ… ç¬¦åˆè§„èŒƒ
- éµå¾ª OpenAI API è§„èŒƒ
- `finish_reason: "tool_calls"` è¡¨ç¤ºå“åº”åŒ…å«å·¥å…·è°ƒç”¨
- Codex ç­‰å®¢æˆ·ç«¯èƒ½æ­£ç¡®è¯†åˆ«

### âœ… é€šç”¨è§£å†³æ–¹æ¡ˆ
- é€‚ç”¨äºæ‰€æœ‰æ£€æŸ¥ `finish_reason` çš„å®¢æˆ·ç«¯
- ä¸éœ€è¦ä¿®æ”¹å®¢æˆ·ç«¯ä»£ç 
- ä¸éœ€è¦é…ç½®ï¼Œè‡ªåŠ¨ç”Ÿæ•ˆ

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### å®ç°ä½ç½®
- **æ ¸å¿ƒé€»è¾‘**: `src/client.rs` - `chat_stream_openai()`
- **æ£€æµ‹**: ç¬¬ 289-300 è¡Œ - æ£€æµ‹ tool_calls
- **ä¿®æ­£**: ç¬¬ 339-360 è¡Œ - ä¿®æ­£ finish_reason

### å…³é”®ä»£ç 

```rust
// æ£€æµ‹ tool_calls
if let Some(first_choice) = stream_chunk.choices.get(0) {
    if let Some(tool_calls) = &first_choice.delta.tool_calls {
        has_tool_calls = true;  // æ ‡è®°
    }
}

// ä¿®æ­£ finish_reason
let finish_reason = if has_tool_calls {
    tracing::info!("ğŸ¯ Setting finish_reason to 'tool_calls'");
    "tool_calls"
} else {
    "stop"
};
```

## ğŸ“š ç›¸å…³èµ„æº

### OpenAI API è§„èŒƒ
- [Streaming Responses](https://platform.openai.com/docs/guides/streaming-responses)
- `finish_reason` å¯èƒ½çš„å€¼ï¼š
  - `"stop"`: æ­£å¸¸ç»“æŸ
  - `"tool_calls"`: éœ€è¦æ‰§è¡Œå·¥å…·
  - `"length"`: è¾¾åˆ°æœ€å¤§é•¿åº¦
  - `"content_filter"`: å†…å®¹è¿‡æ»¤

### Codex æºä»£ç 
- ä»“åº“: https://github.com/openai/codex
- å…³é”®æ–‡ä»¶: `codex-rs/core/src/chat_completions.rs`
- åˆ¤æ–­é€»è¾‘: ç¬¬ 587-640 è¡Œ

## ğŸ¯ æ€»ç»“

**é—®é¢˜**ï¼šGLM-4.6 è¿”å›é”™è¯¯çš„ `finish_reason`  
**åŸå› **ï¼šCodex ä¾èµ– `finish_reason` å†³å®šæ˜¯å¦æ‰§è¡Œå·¥å…·  
**è§£å†³**ï¼šllm-link è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®æ­£ `finish_reason`  
**æ•ˆæœ**ï¼šâœ… ç”¨æˆ·çœ‹åˆ°æ€è€ƒè¿‡ç¨‹ + âœ… å·¥å…·æ­£å¸¸æ‰§è¡Œ

è¿™æ˜¯ä¸€ä¸ª**å®Œç¾çš„ä»£ç†å±‚ä¿®å¤**ï¼Œæ— éœ€ä¿®æ”¹å®¢æˆ·ç«¯æˆ– LLMï¼Œåœ¨ä¸­é—´å±‚è§£å†³äº†å…¼å®¹æ€§é—®é¢˜ï¼ğŸ‰


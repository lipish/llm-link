#!/usr/bin/env bash
set -euo pipefail

if [[ $# -lt 1 ]]; then
  cat <<'USAGE'
ç”¨æ³•ï¼šscripts/start-zed-seed-code.sh <VOLCENGINE_API_KEY> [é™„åŠ  llm-link å‚æ•°]
ç¤ºä¾‹ï¼šscripts/start-zed-seed-code.sh "ark-xxx" --port 18000

è¯¥è„šæœ¬ä¼šä»¥ Ollama åè®®å¯åŠ¨ Zed æœåŠ¡ï¼Œåç«¯ä½¿ç”¨ Volcengine Doubao Seed Codeï¼ˆé€»è¾‘å doubao-seed-code-preview-latestï¼‰ã€‚
å¦‚éœ€æ˜ å°„åˆ°å…·ä½“ ep- æ¥å…¥ç‚¹ï¼Œè¯·åœ¨ä»“åº“æ ¹ç›®å½•é…ç½® model-overrides.yamlã€‚
USAGE
  exit 1
fi

VOLCENGINE_API_KEY="$1"
shift

LLM_LINK_BIN=${LLM_LINK_BIN:-"./target/release/llm-link"}

if [[ ! -x "${LLM_LINK_BIN}" ]]; then
  echo "ğŸ”§ æœªæ‰¾åˆ° ${LLM_LINK_BIN}ï¼Œæ­£åœ¨æ‰§è¡Œ cargo build --release..."
  cargo build --release
fi
MODEL=${MODEL:-"doubao-seed-code-preview-latest"}

args=("$@")
user_model_flag=false
for ((i=0; i<${#args[@]}; i++)); do
  case "${args[$i]}" in
    --model|--model=*)
      user_model_flag=true
      break
      ;;
  esac
done

cmd=(
  "${LLM_LINK_BIN}"
  --app zed
  --protocols ollama
  --provider volcengine
  --llm-api-key "${VOLCENGINE_API_KEY}"
)

if [[ "${user_model_flag}" != true ]]; then
  cmd+=(--model "${MODEL}")
fi

cmd+=("${args[@]}")

exec "${cmd[@]}"
